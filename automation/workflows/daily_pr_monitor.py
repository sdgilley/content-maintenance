"""
Daily PR monitoring workflow

Runs find-prs.py to analyze PRs and optionally auto-approves those in the
"OK to Approve" category (if dry_run is not enabled).
"""

import os
import sys
import logging
import argparse
import subprocess
import json
from typing import Dict, List, Any
from datetime import datetime

# Add parent directory to path for imports
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

from automation.core.config import (
    get_automation_config,
    get_email_config,
    get_pr_approval_config
)
from automation.core.github_client import GitHubClient
from automation.core.reporter import ReportGenerator, EmailSender
from utilities import gh_auth

logger = logging.getLogger(__name__)


class PRApprover:
    """Approves PRs from the OK to Approve list"""
    
    def __init__(self, github_client):
        self.github_client = github_client
    
    def approve_pr(self, repo_full_name: str, pr_number: int, dry_run: bool = True) -> bool:
        """
        Approve a PR
        
        Args:
            repo_full_name: Full repository name (owner/repo)
            pr_number: PR number
            dry_run: If True, don't actually approve
            
        Returns:
            True if successful
        """
        try:
            repo = self.github_client.get_repo(repo_full_name)
            pr = repo.get_pull(pr_number)
            
            comment = (
                "✅ **Auto-approved by content maintenance automation**\n\n"
                "This PR has been automatically validated and approved because:\n"
                "- No deleted files are referenced in documentation\n"
                "- No renamed files are referenced in documentation\n"
                "- No deleted cells/snippets in modified files that are referenced in docs\n\n"
                "If you notice any issues, please add a comment and we'll review."
            )
            
            success = self.github_client.approve_pr(pr, comment, dry_run)
            
            if success:
                logger.info(f"✅ Approved PR #{pr_number} in {repo_full_name}")
            else:
                logger.error(f"Failed to approve PR #{pr_number} in {repo_full_name}")
            
            return success
        except Exception as e:
            logger.error(f"Error approving PR #{pr_number}: {e}")
            return False





def run_find_prs_report(days: int = 14, dry_run: bool = False):
    """
    Run find-prs.py and optionally approve safe PRs
    
    Args:
        days: Look at PRs updated in last N days
        dry_run: If True, only analyze without taking actions
    """
    # Setup logging
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    logger.info("=" * 60)
    logger.info("Starting Daily PR Monitoring Workflow")
    logger.info(f"Dry run mode: {dry_run}")
    logger.info("=" * 60)
    
    approved_prs = []
    manual_review_prs = []
    errors = []
    
    try:
        # Load configurations
        config = get_automation_config()
        email_config = get_email_config()
        pr_config = get_pr_approval_config()
        
        # Override dry_run from config if set
        if pr_config.dry_run:
            dry_run = True
            logger.info("Dry run mode enabled via configuration")
        
        # Run find-prs.py
        logger.info("Running find-prs.py analysis...")
        find_prs_dir = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
        find_prs_script = os.path.join(find_prs_dir, "find-prs.py")
        
        # Generate a JSON report filename
        report_file = f"pr-analysis-{datetime.now().strftime('%Y-%m-%d-%H%M%S')}.json"
        
        # Run find-prs.py with a custom report file
        cmd = [sys.executable, find_prs_script, "--days", str(days)]
        result = subprocess.run(cmd, capture_output=True, text=True, cwd=find_prs_dir)
        
        if result.returncode != 0:
            logger.error(f"find-prs.py failed: {result.stderr}")
            errors.append(f"find-prs.py execution failed: {result.stderr}")
        else:
            logger.info("find-prs.py completed successfully")
        
        # Look for the generated markdown report
        reports_dir = find_prs_dir
        md_reports = sorted([
            f for f in os.listdir(reports_dir)
            if f.startswith('pr-review-report-') and f.endswith('.md')
        ], reverse=True)
        
        if not md_reports:
            logger.warning("No markdown report found from find-prs.py")
            errors.append("No markdown report generated by find-prs.py")
            return
        
        latest_report = os.path.join(reports_dir, md_reports[0])
        logger.info(f"Found latest report: {latest_report}")
        
        # Parse the markdown report to extract PR categorizations
        with open(latest_report, 'r', encoding='utf-8') as f:
            report_content = f.read()
        
        # Extract PRs OK to Approve section
        approved_section = extract_section(report_content, "✅ PRs OK to Approve")
        if approved_section:
            approved_prs = parse_pr_table(approved_section)
            logger.info(f"Found {len(approved_prs)} PRs OK to approve")
        
        # Extract PRs requiring review section
        manual_section = extract_section(report_content, "⚠️ PRs Requiring Further Review")
        if manual_section:
            manual_review_prs = parse_pr_table(manual_section)
            logger.info(f"Found {len(manual_review_prs)} PRs requiring manual review")
        
        # If auto-approval is enabled and not a dry run, approve safe PRs
        if pr_config.auto_approve_enabled and not dry_run and approved_prs:
            logger.info("Auto-approval enabled, approving safe PRs...")
            
            github_client = GitHubClient()
            approver = PRApprover(github_client)
            
            for pr_info in approved_prs:
                repo = pr_info.get('repo')
                pr_number = pr_info.get('number')
                
                if repo and pr_number:
                    success = approver.approve_pr(repo, pr_number, dry_run=False)
                    if success:
                        logger.info(f"✅ Auto-approved PR #{pr_number}")
        elif not pr_config.auto_approve_enabled:
            logger.info("Auto-approval is disabled in configuration")
        elif dry_run:
            logger.info("Dry run mode: skipping PR approvals")
        
        # Generate summary report
        summary_md = generate_summary_report(approved_prs, manual_review_prs, errors, dry_run)
        
        # Save summary to GitHub Actions
        report_gen = ReportGenerator()
        report_gen.write_github_summary(summary_md)
        
        # Send email if configured
        if email_config.is_configured():
            logger.info("Sending email report...")
            email_sender = EmailSender(
                email_config.smtp_server,
                email_config.smtp_port,
                email_config.smtp_username,
                email_config.smtp_password,
                email_config.from_address
            )
            
            subject = f"[Azure AI Docs] Daily PR Monitor - {datetime.now().strftime('%Y-%m-%d')}"
            if dry_run:
                subject = "[DRY RUN] " + subject
            
            email_sender.send_email(
                email_config.to_addresses,
                summary_md,
                summary_md,
                dry_run
            )
            logger.info("Email report sent")
        else:
            logger.info("Email not configured, skipping email notification")
        
        logger.info("=" * 60)
        logger.info("Daily workflow completed successfully")
        logger.info("=" * 60)
        
    except Exception as e:
        logger.error(f"Daily workflow failed: {e}", exc_info=True)
        errors.append(f"Workflow error: {str(e)}")
        raise


def extract_section(content: str, section_title: str) -> str:
    """Extract a section from markdown content by title"""
    lines = content.split('\n')
    start_idx = -1
    
    for i, line in enumerate(lines):
        if section_title in line:
            start_idx = i
            break
    
    if start_idx == -1:
        return ""
    
    # Get lines until next section (## marker) or end of file
    section_lines = []
    for i in range(start_idx + 1, len(lines)):
        if lines[i].startswith('##') and i > start_idx:
            break
        section_lines.append(lines[i])
    
    return '\n'.join(section_lines)


def parse_pr_table(table_content: str) -> List[Dict[str, Any]]:
    """Parse a markdown table to extract PR information"""
    lines = [l.strip() for l in table_content.split('\n') if l.strip() and not l.startswith('|')]
    prs = []
    
    for line in lines:
        if line.startswith('|') and line.endswith('|'):
            cells = [c.strip() for c in line.split('|')[1:-1]]
            
            # Try to extract PR number and repo from the cells
            # Format: [shortname] [#PR](url) [title] [author] [issues]
            if len(cells) >= 2:
                # Look for PR link pattern [#123](url)
                pr_cell = cells[1] if len(cells) > 1 else ""
                repo_cell = cells[0] if len(cells) > 0 else ""
                
                # Extract PR number from [#123](url) format
                import re
                pr_match = re.search(r'\[#(\d+)\]\(([^)]+)\)', pr_cell)
                
                if pr_match:
                    pr_number = int(pr_match.group(1))
                    url = pr_match.group(2)
                    
                    # Extract repo from URL (format: https://github.com/owner/repo/pull/...)
                    repo_match = re.search(r'github\.com/([^/]+)/([^/]+)/pull', url)
                    if repo_match:
                        owner = repo_match.group(1)
                        repo_name = repo_match.group(2)
                        repo = f"{owner}/{repo_name}"
                        
                        prs.append({
                            'number': pr_number,
                            'repo': repo,
                            'url': url,
                            'shortname': repo_cell
                        })
    
    return prs


def generate_summary_report(approved: List[Dict], manual: List[Dict], errors: List[str], dry_run: bool) -> str:
    """Generate a markdown summary report"""
    summary = f"""# Daily PR Monitor Report - {datetime.now().strftime('%Y-%m-%d')}

## Summary
- **Total PRs Analyzed**: {len(approved) + len(manual)}
- **OK to Approve**: {len(approved)}
- **Requiring Manual Review**: {len(manual)}
- **Errors**: {len(errors)}
"""
    
    if dry_run:
        summary += "\n⚠️ **DRY RUN MODE** - No PRs were actually approved\n"
    
    if approved:
        summary += "\n## ✅ PRs OK to Approve\n"
        for pr in approved:
            summary += f"- [#{pr['number']}]({pr['url']}) - {pr['shortname']}\n"
    
    if manual:
        summary += "\n## ⚠️ PRs Requiring Manual Review\n"
        for pr in manual:
            summary += f"- [#{pr['number']}]({pr['url']}) - {pr['shortname']}\n"
    
    if errors:
        summary += "\n## ❌ Errors\n"
        for error in errors:
            summary += f"- {error}\n"
    
    return summary




def main():
    """CLI entry point"""
    parser = argparse.ArgumentParser(description="Daily PR monitoring workflow")
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='Run in dry-run mode (no actual approvals)'
    )
    parser.add_argument(
        '--days',
        type=int,
        default=14,
        help='Look at PRs updated in the last N days (default: 14)'
    )
    args = parser.parse_args()
    
    run_find_prs_report(days=args.days, dry_run=args.dry_run)


if __name__ == '__main__':
    main()
